@book{book:bellman,
address = {Princeton, NJ},
author = {Bellman, Richard Ernest},
publisher = {Princeton University Press},
series = {Rand Corporation research study},
title = {{Dynamic Programming}},
year = {1957}
}

@book{book:ADP,
author = {Stein, Gunter},
booktitle = {Applications of Adaptive Control},
isbn = {9780125140607},
pages = {291--312},
title = {{Adaptive Flight Control - A Pragmatic View}},
year = {1980}
}

@article{ironies,
author = {Bainbridge, Lisanne},
issn = {00051098},
journal = {Automatica},
number = {6},
pages = {775--779},
title = {{Ironies of automation}},
volume = {19},
year = {1983}
}

@inproceedings{NDI,
author = {Lane, Stephen H. and Stengel, Robert F.},
booktitle = {1986 American Control Conference},
month = {jun},
pages = {587--596},
publisher = {IEEE},
title = {{Flight Control Design using Nonlinear Inverse Dynamics}},
year = {1986}
}
@article{Sutton1988,
author = {Sutton, Richard S},
journal = {Machine Learning},
keywords = {Incremental learning,connectionism,credit assignment,evaluation functions,prediction},
pages = {9--44},
title = {{Learning to Predict by the Methods of Temporal Differences}},

volume = {3},
year = {1988}
}
@article{Hornik1989,
author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},

issn = {08936080},
journal = {Neural Networks},
month = {jan},
number = {5},
pages = {359--366},
title = {{Multilayer feedforward networks are universal approximators}},

volume = {2},
year = {1989}
}
@article{Williams1992,
author = {Williams, Ronald J},

issn = {0885-6125},
journal = {Machine Learning},
keywords = {Reinforcement learning,connectionist networks,gradient descent,mathematical analysis},
number = {3-4},
pages = {229--256},
title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},

volume = {8},
year = {1992}
}
@inproceedings{Huber1993,
address = {Cernobbio, Italy},
author = {Huber, Helmut and Hamel, Peter},
booktitle = {Ninteenth European Rotorcraft Forum},
title = {{Helicopter Flight Control System: State of the Art and Future Directions}},
year = {1993}
}
@article{Prokhorov1995,
author = {Prokhorov, Danil V. and Santiago, Roberto A. and Wunsch, Donald C.},

issn = {08936080},
journal = {Neural Networks},
keywords = {Adaptive critic,Aircraft autolanding,Heuristic dynamic programming,Neural networks for control and optimization,Neurocontrol},
number = {9},
pages = {1367--1372},
title = {{Adaptive Critic Designs: A Case Study for Neurocontrol}},
volume = {8},
year = {1995}
}
@article{Balakrishnan1996,
author = {Balakrishnan, S N and Biega, Victor},

journal = {Journal of Guidance, Control, and Dynamics},
number = {4},
title = {{Adaptive-Critic-Based Neural Networks for Aircraft Optimal Control}},

volume = {19},
year = {1996}
}
@inproceedings{Pavel1997,
address = {Dresden},
author = {Pavel, M.D. and van Holten, Th},
booktitle = {23rd European Rotorcraft Forum},
title = {{On the Prediction of the Necessary Dynamics For Helicopter Flight Simulation}},

year = {1997}
}
@article{Tsitsiklis1997,
author = {Tsitsiklis, John N and Roy, Benjamin Van},
journal = {IEEE Transactions on Automatic Control},
keywords = {Index Terms-Dynamic programming,Markov chains,function approxima-tion,neuro-dynamic programming,reinforce-ment learning,temporal-difference learning},
number = {5},
title = {{An Analysis of Temporal-Difference Learning with Function Approximation}},

volume = {42},
year = {1997}
}
@article{Prokhorov1997,
author = {Prokhorov, Danil V. and Wunsch, Donald C.},

issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Adaptive Critic Design (ACD),Backpropagation,Control,DHP,Dynamic programming,GDHP,HDP,Heuristic dynamic programming,Neural network,Neurocontrol,Reinforcement learning},
number = {5},
pages = {997--1007},
title = {{Adaptive Critic Designs}},

volume = {8},
year = {1997}
}
@article{Bertsekas2000,
author = {Bertsekas, Dimitri P and Homer, Mark L and Logan, David A and Patek, Stephen D and Sandell, Nils R},
journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
number = {1},
title = {{Missile Defense and Interceptor Allocation by Neuro-Dynamic Programming}},

volume = {30},
year = {2000}
}
@article{Marbach2001,
author = {Marbach, Peter and Tsitsiklis, John N},
isbn = {00189286/01{\$}10.0},
journal = {IEEE Transactions on Automatic Control},
number = {2},
title = {{Simulation-Based Optimization of Markov Reward Processes}},

volume = {46},
year = {2001}
}
@inproceedings{Bagnell2001,
address = {Seoul, South Korea},
author = {Bagnell, J.A. and Schneider, J.G.},
booktitle = {Proceedings of the 2001 IEEE International Conference on Robotics and Automation},

isbn = {0-7803-6576-3},
pages = {1615--1620},
publisher = {IEEE},
title = {{Autonomous helicopter control using reinforcement learning policy search methods}},

year = {2001}
}
@article{Si2001,
author = {Si, Jennie and Member, Senior and Wang, Yu-Tsung},
journal = {IEEE Transactions on Neural Networks},
number = {2},
title = {{On-Line Learning Control by Association and Reinforcement}},

volume = {12},
year = {2001}
}
@inproceedings{Kakade2002,
address = {Sydney, Australia},
author = {Kakade, Sham and Landford, John},
booktitle = {Proceedings of the 19th International Conference on Machine Learning},
title = {{Approximately Optimal Approximate Reinforcement Learning}},

year = {2002}
}
@article{Dai2002,
author = {Dai, Jiyang and Mao, Jianqin},

issn = {14746670},
journal = {IFAC Proceedings Volumes},
number = {1},
pages = {73--78},
title = {{Robust Flight Controller Design for Helicopters Based on Genetic Algorithms}},

volume = {35},
year = {2002}
}
@article{Venayagamoorthy2002,
author = {Venayagamoorthy, Ganesh K and Harley, Ronald G and Wunsch, Donald C},
journal = {IEEE Transactions on Neural Networks},
keywords = {Index Terms-Adaptive critics,artificial neural networks (ANNs),neurocontrol,optimal control,turbogenerator control},
number = {3},
title = {{Comparison of Heuristic Dynamic Programming and Dual Heuristic Programming Adaptive Critics for Neurocontrol of a Turbogenerator}},

volume = {13},
year = {2002}
}
@article{Enns2002,
author = {Enns, Russell and Si, Jennie},

issn = {07315090},
journal = {Journal of Guidance, Control, and Dynamics},
number = {1},
pages = {19--25},
publisher = {American Inst. Aeronautics and Astronautics Inc.},
title = {{Apache Helicopter Stabilization Using Neural Dynamic Programming}},
volume = {25},
year = {2002}
}
@misc{book:holten,
author = {van Holten, Th.},
isbn = {1575242095},
number = {November},
pages = {746},
title = {{Helicopter Performance, Stability and Control}},
year = {2002}
}
@techreport{Ng2003,
author = {Ng, Andrew Y and Kim, H Jin and Jordan, Michael I and Sastry, Shankar},
title = {{Autonomous helicopter flight via reinforcement learning}},
year = {2003}
}
@article{Enns2003b,
author = {Enns, Russell and Si, Jennie},

issn = {07315090},
journal = {Journal of Guidance, Control, and Dynamics},
number = {4},
pages = {572--584},
publisher = {American Inst. Aeronautics and Astronautics Inc.},
title = {{Helicopter flight-control reconfiguration for main rotor actuator failures}},
volume = {26},
year = {2003}
}
@article{Enns2003a,
author = {Enns, Russell and Si, Jennie},

journal = {IEEE Transactions on Neural Networks},
keywords = {Approximate dynamic programming,flight control,helicopter,helicopter trim,neural dynamic programming},
number = {4},
pages = {929--939},
publisher = {IEEE},
title = {{Helicopter Trimming and Tracking Control Using Direct Neural Dynamic Programming}},

volume = {14},
year = {2003}
}
@article{Ferrari2004,
author = {Ferrari, Silvia and Stengel, Robert F},

journal = {Journal of Guidance, Control, and Dynamics},
number = {5},
title = {{Online Adaptive Critic Flight Control}},

volume = {27},
year = {2004}
}
@inproceedings{Stiles2004,
address = {Baltimore, MD},
author = {Stiles, L.R. and Mayo, John and Freisner, A. Lynn and Landis, Kenneth H. and Kothmann, Bruce D},
booktitle = {American Helicopter Society 60th Annual Forum},

pages = {1--18},
title = {{"Impossible To Resist", the development of rotorcraft fly-by-wire technology}},
year = {2004}
}
@incollection{RLHeli:hover,
author = {Kim, H J and Jordan, Michael I and Sastry, Shankar and Ng, Andrew Y},
booktitle = {Advances in Neural Information Processing Systems 16},
editor = {Thrun, S and Saul, L K and Sch{\"{o}}lkopf, B},
pages = {799--806},
publisher = {MIT Press},
title = {{Autonomous Helicopter Flight via Reinforcement Learning}},

year = {2004}
}
@inproceedings{RLHeli:inverted,
address = {Singapore},
author = {Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
booktitle = {International Symposium on Experimental Robotics},
title = {{Autonomous inverted helicopter flight via reinforcement learning}},
year = {2004}
}
@inproceedings{VanKampen2006,
address = {Keystone, CO},
author = {van Kampen, Erik-Jan and Chu, Q.P. and Mulder, J.A.},
booktitle = {AIAA Guidance, Navigation, and Control Conference},

isbn = {978-1-62410-046-8},
month = {aug},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Continuous Adaptive Critic Flight Control Aided with Approximated Plant Dynamics}},

year = {2006}
}
@inproceedings{Harding2006,
address = {PHoenix, AZ},
author = {Harding, Jeffrey W and Moody, Scott J and Jeram, Geoffrey J and Mansur, M Hossein and Tischler, Mark B},
booktitle = {American Helicopter Society 62nd Annual Forum},
title = {{Development of Modern Control Laws for the AH-64D in Hover/Low Speed Flight}},

year = {2006}
}
@incollection{RLHeli:aerobatics,
address = {Van},
author = {Abbeel, Pieter and Coates, Adam and Quigley, Morgan and Ng, Andrew Y},
booktitle = {Advances in Neural Information Processing Systems 19},
editor = {Sch{\"{o}}lkopf, B and Platt, J C and Hoffman, T},
pages = {1--8},
publisher = {MIT Press},
title = {{An Application of Reinforcement Learning to Aerobatic Helicopter Flight}},

year = {2007}
}
@inproceedings{RLHeli:autorotation,
address = {Seoul, South Korea},
author = {Abbeel, Pieter and Coates, Adam and Hunter, Timothy and Ng, Andrew Y},
booktitle = {International Symposium on Robotics},
title = {{Autonomous Autorotation of an RC Helicopter}},

year = {2008}
}
@inproceedings{RLHeli:extreme,
address = {Helsinki, Finland},
author = {Coates, Adam and Abbeel, Pieter and Ng, Andrew Y},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
title = {{Learning for Control from Multiple Demonstrations}},

year = {2008}
}
@book{book:algorithms4rl,
author = {Szepesv{\'{a}}ri, Csaba},
booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
issn = {1939-4608},
month = {jan},
number = {1},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
volume = {4},
year = {2010}
}
@book{book:seddon,
author = {Seddon, John and Newman, Simon},
edition = {2},
isbn = {063205283X},
publisher = {Blackwell Science},
title = {{Basic Helicopter Aerodynamics}},
year = {2011}
}
@book{book:autorotations,
address = {Oregonia OH},
author = {Coyle, Shawn C},
edition = {First},
pages = {112},
publisher = {Eagle Eye Solutions LLC},
title = {{Little Book of Autorotations}},
year = {2012}
}
@book{book:faarotorcraft,
author = {{Federal Aviation Administration} and {U.S. Department of Transportation}},
isbn = {978-1629145914},
publisher = {Skyhorse Publishing},
title = {{Rotorcraft Flying Handbook}},
year = {2012}
}
@inproceedings{Acquatella2012,
address = {Reston, Virigina},
author = {Acquatella, Paul and Falkena, Wouter and van Kampen, Erik-Jan and Chu, Q. Ping},
booktitle = {AIAA Guidance, Navigation, and Control Conference},

isbn = {978-1-60086-938-9},
month = {aug},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Robust Nonlinear Spacecraft Attitude Control using Incremental Nonlinear Dynamic Inversion.}},

year = {2012}
}
@inproceedings{IBS,
address = {Delft, The Netherlands},
author = {Acquatella, Paul and {Van Kampen}, Erik-Jan and Chu, Qi Ping},
booktitle = {Proceedings of the EuroGNC},
title = {{Incremental Backstepping for Robust Nonlinear Flight Control}},
year = {2013}
}
@article{Mnih2013,
archivePrefix = {arXiv},
arxivId = {1312.5602v1},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
eprint = {1312.5602v1},
journal = {arXiv e-prints},
title = {{Playing Atari with Deep Reinforcement Learning}},

year = {2013}
}
@article{Meng2013,
author = {Meng, Wanli and Chen, Renliang},

issn = {10009361},
journal = {Chinese Journal of Aeronautics},
keywords = {Autorotation landing,Engine failure,Helicopters,Optimal control,Rigid-body model},
number = {6},
pages = {1380--1388},
publisher = {Chinese Society of Aeronautics and Astronautics},
title = {{Study of helicopter autorotation landing following engine failure based on a six-degree-of-freedom rigid-body dynamic model}},

volume = {26},
year = {2013}
}
@article{Simplicio2013,
author = {Simpl{\'{i}}cio, P and van Kampen, E and Chu, QP},

journal = {Control Engineering Practice},
keywords = {Flight control,Helicopter,Incremental Nonlinear Dynamic Inversion,Nonlinear control,Pseudo-Control Hedging},
number = {8},
pages = {1065--1077},
title = {{An acceleration measurements-based approach for helicopter nonlinear flight control using Incremental Nonlinear Dynamic Inversion}},

volume = {21},
year = {2013}
}
@inproceedings{Silver2014,
address = {Beijing, China},
author = {Silver, David and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
booktitle = {Proceedings of the 31st International Conference on Machine Learning},
title = {{Deterministic Policy Gradient Algorithms}},
year = {2014}
}
@inproceedings{Schulman2015,
address = {Lille, France},
archivePrefix = {arXiv},
arxivId = {1502.05477},
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML)},
eprint = {1502.05477},
pages = {1889--1897},
title = {{Trust Region Policy Optimization}},

year = {2015}
}
@phdthesis{Taamalllah2015,
author = {Taamalllah, Skanker},
isbn = {978-94-6259-831-7},
keywords = {Automatic Autoro- tation,Linear Parameter Vary- ing Systems,Small-Scale Helicopter,Trajectory Planning,Trajectory Tracking,Unmanned Aerial Vehicles},
school = {Delft University of Technology},
title = {{Small-Scale Helicopter Automatic Autorotation}},
year = {2015}
}
@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},

journal = {Nature},
pages = {529--533},
title = {{Human-level control through deep reinforcement learning}},

volume = {518},
year = {2015}
}
@inproceedings{Schulman2016,
archivePrefix = {arXiv},
arxivId = {1506.02438v6},
author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I and Abbeel, Pieter},
booktitle = {International Conference on Learning Representations (ICLR)},
eprint = {1506.02438v6},
isbn = {1506.02438v6},
title = {{High-dimensional Continuous Control Using Generalized Advantage Estimation}},

year = {2016}
}
@article{Chen2016,
author = {Chen, Mou and Shi, Peng and Lim, Cheng-Chew and Member, Senior},

journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
number = {2},
title = {{Adaptive Neural Fault-Tolerant Control of a 3-DOF Model Helicopter System}},

volume = {46},
year = {2016}
}
@techreport{IHST,
address = {Louisville, Kentucky, USA},
author = {IHSTI-CIS},
institution = {International Helicopter Safety Team},
title = {{Helicopter accidents: statistics, trends and causes}},

year = {2016}
}
@inproceedings{Schaul2016,
archivePrefix = {arXiv},
arxivId = {1511.05952v4},
author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David and Deepmind, Google},
booktitle = {Proceedings of the 34th International Conference on Learning Representations (ICLR)},
eprint = {1511.05952v4},
isbn = {1511.05952v4},
title = {{Prioritized Experience Replay}},

year = {2016}
}
@inproceedings{Duan2016,
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1604.06778},
author = {Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
eprint = {1604.06778},
title = {{Benchmarking Deep Reinforcement Learning for Continuous Control}},

year = {2016}
}
@inproceedings{Hasselt2016,
archivePrefix = {arXiv},
arxivId = {1606.04615},
author = {Hasselt, Hado Van and Guez, Arthur and Silver, David},
booktitle = {Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-16)},
eprint = {1606.04615},
keywords = {Technical Papers: Machine Learning Methods},
pages = {2094--2100},
title = {{Deep Reinforcement Learning with Double Q-Learning}},
year = {2016}
}
@inproceedings{Ma2016,
address = {Ansan, Korea},
author = {Ma, Shidong and Yang, Guoqing},
booktitle = { International Conference on Control, Automation and Information Sciences (ICCAIS)},
isbn = {9781509006502},
title = {{Helicopter Nonlinear Dynamic Inversion Flight Control Model Design}},
year = {2016}
}
@inproceedings{Mnih2016,
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1602.01783},
author = {Mnih, Volodymyr and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
eprint = {1602.01783},
isbn = {1602.01783v2},
title = {{Asynchronous Methods for Deep Reinforcement Learning}},
year = {2016}
}
@inproceedings{Lillicrap2015,
archivePrefix = {arXiv},
arxivId = {1509.02971v5},
author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
booktitle = {International Conference on Learning Representations (ICLR)},
eprint = {1509.02971v5},
title = {{Continuous Control with Deep Reinforcement Learning}},
year = {2016}
}
@article{Zhou2016HDP,
author = {Zhou, Ye and {Van Kampen}, Erik-Jan and Chu, Q},
journal = {Proceedings of the international micro air vehicles conference and competition (IMAV) 2016},
title = {{Incremental Model Based Heuristic Dynamic Programming for Nonlinear Adaptive Flight Control}},
year = {2016}
}
@article{Zhou2016iADP,
author = {Zhou, Ye and van Kampen, Erik-Jan and Chu, QiPing},
issn = {0731-5090},
journal = {Journal of Guidance, Control, and Dynamics},
number = {2},
pages = {493--500},
title = {{Nonlinear Adaptive Flight Control Using Incremental Approximate Dynamic Programming and Output Feedback}},
volume = {40},
year = {2016}
}
@inproceedings{HindsightER,
address = {Long Beach, CA, USA},
archivePrefix = {arXiv},
arxivId = {1707.01495v3},
author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
booktitle = {Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS)},
eprint = {1707.01495v3},
title = {{Hindsight Experience Replay}},

year = {2017}
}
@inproceedings{Wu2017:ACKTR,
address = {Long Beach, CA, USA},
archivePrefix = {arXiv},
arxivId = {1708.05144},
author = {Wu, Yuhuai and Mansimov, Elman and Liao, Shun and Grosse, Roger and Ba, Jimmy},
booktitle = {31st Conference on Neural Information Processing Systems (NIPS)},
eprint = {1708.05144},
title = {{Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation}},
year = {2017}
}
@article{Arulkumaran2017,
author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
journal = {IEEE Signal Processing Magazine},
keywords = {artificial intelligence},
number = {6},
pages = {26--38},
title = {{Deep Reinforcement Learning: A brief survey}},
volume = {34},
year = {2017}
}
@inproceedings{Hessel2017,
archivePrefix = {arXiv},
arxivId = {1710.02298},
author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
eprint = {1710.02298},
isbn = {1710.02298v1},
issn = {15205126},
month = {oct},
title = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
year = {2017}
}
@article{Schulman2017,
archivePrefix = {arXiv},
arxivId = {1707.06347},
author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
eprint = {1707.06347},
journal = {arXiv e-prints},
title = {{Proximal Policy Optimization Algorithms}},
year = {2017}
}
@article{Hu2017,
author = {Hu, Jinshuo and Gu, Hongbin},
issn = {1687-5966},
journal = {International Journal of Aerospace Engineering},
number = {1},
pages = {1--14},
title = {{Survey on Flight Control Technology for Large-Scale Helicopter}},
volume = {2017},
year = {2017}
}
@techreport{EASA,
author = {Ky, Patrick},
institution = {European Aviation Safety Agency},
title = {{EASA Annual Safety Review}},
year = {2018}
}
@inproceedings{VanHasselt2018,
address = {Montreal, Canada},
archivePrefix = {arXiv},
arxivId = {1812.02648},
author = {van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
booktitle = {Deep RL Workshop NeurIPS},
eprint = {1812.02648},
title = {{Deep Reinforcement Learning and the Deadly Triad}},
year = {2018}
}
@inproceedings{Fujimoto2018,
address = {Stockholm, Sweden},
archivePrefix = {arXiv},
arxivId = {1802.09477v3},
author = {Fujimoto, Scott and {Van Hoof}, Herke and Meger, David},
booktitle = {Proceedings of the 35th International Conference on Machine Learning},
eprint = {1802.09477v3},
title = {{Addressing Function Approximation Error in Actor-Critic Methods}},
year = {2018}
}
@book{book:suttonbarto,
address = {Cambridge, Massachusetts},
author = {Sutton, Richard S. and Barto, Andrew G.},
edition = {2},
isbn = {9780262039246},
publisher = {The MIT Press},
title = {{Reinforcement Learning: An Introduction}},
year = {2018}
}
@article{Silver2018,
author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
journal = {Science},
number = {6419},
pages = {1140--1144},
title = {{A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play}},
volume = {362},
year = {2018}
}
@article{Zhou2018DHP,
author = {Zhou, Ye and van Kampen, Erik-Jan and Chu, Qi Ping},
issn = {09670661},
journal = {Control Engineering Practice},
month = {apr},
pages = {13--25},
title = {Incremental Model Based Online Dual Heuristic Programming for Nonlinear Adaptive Control},
volume = {73},
year = {2018}
}
@article{Zhou2018PO,
author = {Zhou, Ye and van Kampen, Erik-Jan and Chu, QiPing},
issn = {0731-5090},
journal = {Journal of Guidance, Control, and Dynamics},
month = {dec},
number = {12},
pages = {2554--2567},
title = {{Incremental Approximate Dynamic Programming for Nonlinear Adaptive Tracking Control with Partial Observability}},
volume = {41},
year = {2018}
}
@article{Parisi2019,
archivePrefix = {arXiv},
arxivId = {1802.07569v4},
author = {Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
eprint = {1802.07569v4},
journal = {Neural Networks},
keywords = {Continual learning,catastrophic forgetting,lifelong learning,memory consolidation},
pages = {54--71},
title = {{Continual Lifelong Learning with Neural Networks: A Review}},
volume = {113},
year = {2019}
}
@inproceedings{Keijzer2019,
address = {San Diego, California},
author = {Keijzer, Twan and Looye, Gertjan and Chu, Qiping and {Van Kampen}, Erik-Jan},
booktitle = {AIAA Scitech Forum},
title = {{Flight Testing of Incremental Backstepping based Control Laws with Angular Accelerometer Feedback}},
year = {2019}
}
@inproceedings{Pollack2019,
address = {Reston, Virginia},
author = {Pollack, Tijmen and Looye, Gertjan and {Van der Linden}, Frans},
booktitle = {AIAA Scitech Forum},
isbn = {978-1-62410-578-4},
month = {jan},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Design and flight testing of flight control laws integrating incremental nonlinear dynamic inversion and servo current control}},
year = {2019}
}
@inproceedings{Heyer2020,
author = {Heyer, Stefan and Kroezen, Dave and {Van Kampen}, Erik-Jan},
booktitle = {AIAA SciTech Forum},
number = {January},
title = {{Online Adaptive Incremental Reinforcement Learning Flight Control for a CS-25 Class Aircraft}},
year = {2020}
}

@techreport{OEILandings,
author = {Chen, Robert T N and Zhao, Yiyuan},
file = {:home/bart/Documents/Mendeley Desktop/Chen, Zhao - 1996 - Optimal Trajectories for the Helicopter in One-Engine-Inoperative Terminal-Area Operations.pdf:pdf},
institution = {NASA Ames Research Center},
mendeley-groups = {Thesis/Articles/Helicopters,Thesis/Paper},
month = {may},
title = {{Optimal Trajectories for the Helicopter in One-Engine-Inoperative Terminal-Area Operations}},
year = {1996}
}
@techreport{BO105DataSheet,
author = {{European Aviation Safety Agency}},
file = {:home/bart/Documents/Mendeley Desktop/European Aviation Safety Agency - 2009 - Type Certificate Data Sheet R.011 BO105.pdf:pdf},
mendeley-groups = {Thesis/Articles/Helicopters,Thesis/Paper},
title = {{Type Certificate Data Sheet R.011 BO105}},
year = {2009}
}

@techreport{ADS33,
key={ADS-33E-PRF},
title = {{Aeronautical Design Standard, Performance Specification, Handling Qualities Requirements for Military Rotorcraft}},
institution = {United States Army Aviation and Missile Command},
year={2000},
address = {Redstone Arsenal, Alabama, USA}
}

@book{book:padfield,
  title={Helicopter Flight Dynamics: The Theory and Application of Flying Qualities and Simulation Modeling},
  author={G. D. Padfield},
  isbn={9781563472053},
  lccn={95000657},
  series={AIAA education series},
  year={1996},
  publisher={American Institute of Aeronautics and Astronautics}
}

@techreport{Gille2006,
title={Flight Mechanics Exercise, Simulation of a One-Engine-Inoperative helicopter landing},
author = {Michael Gille},
institution = {Delft University of Technology},
year = {2006},

}

@techreport{VanDerVorst2001,
author = {{Van Der Vorst}, J},
institution = {Nationaal Lucht- en Ruimtevaartlaboratorium (NLR)},
title = {{A pilot model for helicopter manoeuvres}},
year = {2001}
}

@article{INDI,
author = {Sieberling, S and Chu, Q. P. and Mulder, J. A.},
file = {:home/bart/Documents/Mendeley Desktop/Sieberling, Chu, Mulder - 2010 - Robust Flight Control Using Incremental Nonlinear Dynamic Inversion and Angular Acceleration Prediction.pdf:pdf},
journal = {Journal of Guidance, Control, and Dynamics},
mendeley-groups = {Thesis/Paper},
month = {nov},
number = {6},
title = {{Robust Flight Control Using Incremental Nonlinear Dynamic Inversion and Angular Acceleration Prediction}},
volume = {33},
year = {2010}
}

@inproceedings{BS,
address = {Reston, Virigina},
author = {Sonneveldt, Lars and {Van Oort}, E. R. and Chu, Q. P. and {De Visser}, C. C. and Mulder, J. A. and Breeman, J. H.},
booktitle = {AIAA Guidance, Navigation, and Control Conference and Exhibit},
mendeley-groups = {Thesis/Articles},
month = {aug},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Lyapunov-based fault tolerant flight control designs for a modern fighter aircraft model}},
year = {2009}
}

@inproceedings{Lee2019,
abstract = {The use of target networks has been a popular and key component of recent deep Q-learning algorithms for reinforcement learning, yet little is known from the theory side. In this work, we introduce a new family of target-based temporal difference (TD) learning algorithms that maintain two separate learning parameters-the target variable and online variable. We propose three members in the family, the averaging TD, double TD, and periodic TD, where the target variable is updated through an averaging, symmetric, or periodic fashion, respectively, mirroring those techniques used in deep Q-learning practice. We establish asymptotic convergence analyses for both averaging TD and double TD and a finite sample analysis for periodic TD. In addition, we provide some simulation results showing potentially superior convergence of these target-based TD algorithms compared to the standard TD-learning. While this work focuses on linear function approximation and policy evaluation setting, we consider this as a meaningful step towards the theoretical understanding of deep Q-learning variants with target networks.},
address = {Long Beach, CA},
author = {Lee, Donghwan and He, Niao},
booktitle = {Proceedings of the 36th International Conference on Machine Learning},
mendeley-groups = {Thesis/Paper},
title = {{Target-Based Temporal-Difference Learning}},
year = {2019}
}
